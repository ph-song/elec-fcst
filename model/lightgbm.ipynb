{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b345a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightgbm import Dataset, train, early_stopping\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b9584",
   "metadata": {},
   "source": [
    "## Training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c6713ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= pd.read_csv(\"./data/cleaned_actual.csv\")\n",
    "df_train = df_train.rename(columns={\"Time\": 'time', \n",
    "                                 \"Load (kW)\": \"load_kw_true\", \n",
    "                                 \"Pressure_kpa\": \"pres_kpa_true\",\n",
    "                                 'Cloud Cover (%)': 'cld_pct_true',\n",
    "                                 'Humidity (%)': 'hmd_pct_true',\n",
    "                                 'Temperature (C)': 'temp_c_true',\n",
    "                                 'Wind Direction (deg)': 'wd_deg_true',\n",
    "                                 'Wind Speed (kmh)':'ws_kmh_true'})\n",
    "df_train['time'] = pd.to_datetime(df_train['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d057112",
   "metadata": {},
   "source": [
    "## Testing data and Validation data\n",
    "`./data/cleaned_actual_train_test.csv` contain training and testing data which missing testing data is inputed with naive method. First the data is shifted, then extract the testing data, which is after 2021-01-17 08:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb7d3d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputed testing and training data set\n",
    "df_full= pd.read_csv(\"./data/cleaned_actual_train_test.csv\")\n",
    "df_full = df_full.rename(columns={\"Time\": 'time', \n",
    "                                 \"Pressure (kpa)\": \"pres_kpa_pred\",\n",
    "                                 'Cloud Cover (%)': 'cld_pct_pred',\n",
    "                                 'Temperature (C)': 'temp_c_pred',\n",
    "                                 'Wind Direction (deg)': 'wd_deg_pred',\n",
    "                                 'Wind Speed (kmh)':'ws_kmh_pred'})\n",
    "df_full['time'] = pd.to_datetime(df_full['time'])\n",
    "df_full.set_index('time', inplace=True)\n",
    "df_full.index = df_full.index.tz_convert('+11:00')\n",
    "#df_test.to_csv(\"./data/cleaned_actual_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72efe281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.set_index('time', inplace=True)\n",
    "#df_train.index = df_train.index.tz_convert('+11:00')\n",
    "#df_train.to_csv(\"./data/cleaned_actual_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "412f7ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start and end date of training and validation data\n",
    "end_date = pd.to_datetime(df_train['time'].iloc[-1])\n",
    "start_date = end_date - pd.DateOffset(years=3)\n",
    "\n",
    "#extract 3 years of data, which is training and validation data\n",
    "train_val_data = df_train.loc[df_train['time'].between(start_date, end_date)]\n",
    "\n",
    "#drop time axis\n",
    "train_val_data.index = train_val_data['time']\n",
    "train_val_data = train_val_data.drop('time', axis=1)\n",
    "\n",
    "#split training and validation data \n",
    "n = len(train_val_data)\n",
    "train_data = train_val_data[:int(n*0.9)]\n",
    "val_data= train_val_data[int(n*0.9):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d0d880",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd48dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGBM():\n",
    "    param_grid = [\n",
    "        {'max_depth': depth, 'num_leaves': num_leaves, 'learning_rate': lr, 'subsample': subsample, \n",
    "        'colsample_bytree': colsample_bytree, 'objective': 'regression', 'metric': 'mae', 'verbose':-1}\n",
    "        for depth in range(2, 11, 2)\n",
    "        for num_leaves in [7, 15, 31]\n",
    "        for lr in [i / 10 for i in range(1, 4)]\n",
    "        for subsample in [i / 10 for i in range(5, 11)]\n",
    "        for colsample_bytree in [i / 10 for i in range(5, 11)]\n",
    "    ]\n",
    "\n",
    "    def __init__(self, history_data: pd.DataFrame = False, model_file=\"\"):\n",
    "        if model_file:\n",
    "            self.model = lgb.Booster(model_file=model_file)\n",
    "        else:\n",
    "            self.train_data, self.val_data = self.preprocess(history_data)\n",
    "            self.model, self.params, self.mae = self.train_best_model(self.train_data, self.val_data, self.param_grid)\n",
    "\n",
    "    \n",
    "    def preprocess(self, history_data, lgb_pred = None):\n",
    "        if lgb_pred == None:\n",
    "            lgb_pred = []\n",
    "            \n",
    "        train_val_data = pd.DataFrame([])\n",
    "        for i in range(24, 169, 24):\n",
    "            key = 'load_kw_lag' + str(i)\n",
    "            shift_col =  history_data['load_kw'].shift(i).rename(key)\n",
    "            train_val_data = pd.concat([train_val_data, shift_col], axis=1)\n",
    "            #train_val_data[key] = history_data['load_kw'].shift(i)\n",
    "\n",
    "        train_val_data = pd.concat([train_val_data, history_data['load_kw']], axis=1)\n",
    "        #train_val_data['load_kw'] = history_data['load_kw']\n",
    "\n",
    "        #train_val_data = train_val_data.drop('time_lag168', axis=1) #drop time_lag168\n",
    "        #train_val_data.index = history_data.index #retrieve 'time' as index\n",
    "\n",
    "        train_val_data= train_val_data.dropna(axis=0) #drop rows with NA values (due to shift)\n",
    "\n",
    "\n",
    "        n = len(train_val_data)\n",
    "        return train_val_data[:int(n*0.9)], train_val_data[int(n*0.9):]\n",
    "\n",
    "    def predict(self, history_data, lgb_pred=None):\n",
    "        if lgb_pred == None:\n",
    "            lgb_pred = []\n",
    "        X_pred = pd.DataFrame([])\n",
    "        for i in range(0, 145, 24): #lag24,lag48, ..., lag168\n",
    "            #shift load \n",
    "            X_pred = pd.concat([X_pred, history_data['load_kw'].shift(i).rename('load_kw_lag' + str(i+24))], axis=1)\n",
    "    \n",
    "        #X_pred['load_kw'] = history_data['load_kw']\n",
    "        X_pred = X_pred.dropna(axis=0)\n",
    "        X_pred.index = X_pred.index + pd.Timedelta(hours=24) #shift index time\n",
    "        \n",
    "        for i in range(len(X_pred)):\n",
    "            #time = time_now + timedelta(hours=i) #increment 'time'\n",
    "            X = X_pred.iloc[i,:] #1 hour of predictors\n",
    "            lgb_pred.append(float(self.model.predict(X)))\n",
    "\n",
    "        if len(lgb_pred) <=24:\n",
    "            new_df = pd.DataFrame({'load_kw':lgb_pred}, index=pd.date_range(history_data.index[-1] + pd.Timedelta(hours=1), periods=len(lgb_pred), freq='H'))\n",
    "            history_data = pd.concat([history_data, new_df])\n",
    "            return self.predict(history_data[24:], lgb_pred=lgb_pred)\n",
    "        \n",
    "        else:\n",
    "            return lgb_pred\n",
    "    \n",
    "    def train_best_model(self, train_data, val_data, param_grid):\n",
    "        \"\"\"\n",
    "        This function trains a LightGBM model using a grid search over the parameter grid \n",
    "        and returns the model with the smallest mean absolute error (MAE) on the validation data.\n",
    "        \n",
    "        Args:\n",
    "        train_data (pd.DataFrame): The training data.\n",
    "        val_data (pd.DataFrame): The validation data.\n",
    "        param_grid (dict): The grid of parameters to search over.\n",
    "        \n",
    "        Returns:\n",
    "        best_model (lgb.Booster): The model with the smallest MAE on the validation data.\n",
    "        best_params (dict): The parameters of the best model.\n",
    "        best_mae (float): The MAE of the best model on the validation data.\n",
    "        \"\"\"\n",
    "        best_model = None\n",
    "        best_params = None\n",
    "        best_mae = float('inf')\n",
    "        \n",
    "        # Extract features and labelsx\n",
    "        X_train = train_data.loc[:, ~train_data.columns.isin(['load_kw'])]\n",
    "        y_train = train_data['load_kw']\n",
    "        X_val = val_data.loc[:, ~val_data.columns.isin(['load_kw'])]\n",
    "        y_val = val_data['load_kw']\n",
    "        #print(X_train.info(), y_train.info())\n",
    "        \n",
    "        # Create LightGBM datasets\n",
    "        dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "        dval = lgb.Dataset(X_val, label=y_val)\n",
    "        \n",
    "        print('training model: Light GBM')\n",
    "\n",
    "        # Iterate over all combinations of parameters\n",
    "        for params in tqdm(param_grid):\n",
    "            model = lgb.train(params, dtrain, num_boost_round=100, \n",
    "                            callbacks = [early_stopping(stopping_rounds = 10, verbose=False)],\n",
    "                            valid_sets=[dval])\n",
    "            \n",
    "            # Predict on validation set and calculate MAE\n",
    "            val_preds = model.predict(X_val)\n",
    "            mae = mean_absolute_error(y_val, val_preds)\n",
    "            \n",
    "            # Update best model if current model has lower MAE\n",
    "            if mae < best_mae:\n",
    "                best_model = model\n",
    "                best_params = params\n",
    "                best_mae = mae\n",
    "\n",
    "\n",
    "        return best_model, best_params, best_mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "985ad41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_lgb = LightGBM(history_data = train_val_data)\n",
    "#model_lgb.model.save_model('./lgb_model.txt') #save model\n",
    "model_lgb = LightGBM(model_file=\"./lgb_model.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea075de",
   "metadata": {},
   "source": [
    "## First 24 hour Prediction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f58f4da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lags\n",
    "test_data_1 = pd.DataFrame([])\n",
    "for i in range(24, 169, 24): #lag24,lag48, ..., lag168\n",
    "    #shift load \n",
    "    test_data_1 = pd.concat([test_data_1, df_full['load_kw'].shift(i).rename('load_kw_lag' + str(i))], axis=1)\n",
    "test_data_1 = pd.concat([test_data_1, df_full['load_kw']], axis=1) #extract label\n",
    "\n",
    "#starting date of testing data\n",
    "test_data_start_time = pd.to_datetime('2021-01-17 08:00:00').tz_localize('UTC').tz_convert('+11:00')\n",
    "\n",
    "#extract testing data\n",
    "test_data_1 = test_data_1[test_data_1.index >= test_data_start_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bd55a27",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m y_test_1 \u001b[38;5;241m=\u001b[39m test_data_1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_kw\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m y_pred_1 \u001b[38;5;241m=\u001b[39m model_lgb\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mxgb\u001b[49m\u001b[38;5;241m.\u001b[39mDMatrix(test_data_1\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_kw\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m      3\u001b[0m mae1 \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_test_1, y_pred_1)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(mae1)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "y_test_1 = test_data_1['load_kw']\n",
    "y_pred_1 = model_cat.model.predict(test_data_2.drop('load_kw', axis=1))\n",
    "y_pred_1 = model_lgb.model.predict(xgb.DMatrix(test_data_1.drop('load_kw', axis=1)))\n",
    "mae1 = mean_absolute_error(y_test_1, y_pred_1)\n",
    "print(mae1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = list(y_test_1.index)\n",
    "plt.plot(list(y_test_1))\n",
    "plt.plot(y_pred_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e842abf3",
   "metadata": {},
   "source": [
    "## Last 24 Hour Prediction Data\n",
    "24 hour lag is imputed with predicted data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5005f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lags\n",
    "test_data_2 = pd.DataFrame([])\n",
    "for i in range(24, 145, 24): #lag24,lag48, ..., lag168\n",
    "    #shift load \n",
    "    test_data_2 = pd.concat([test_data_2, df_full['load_kw'].shift(i).rename('load_kw_lag' + str(i+24))], axis=1)\n",
    "test_data_2 = pd.concat([test_data_2, df_full['load_kw']], axis=1) #extract label\n",
    "\n",
    "#starting date of testing data\n",
    "test_data_start_time = pd.to_datetime('2021-01-17 08:00:00').tz_localize('UTC').tz_convert('+11:00')\n",
    "\n",
    "#extract testing data\n",
    "test_data_2 = test_data_2[test_data_2.index >= test_data_start_time]\n",
    "\n",
    "#24 hour lag is imputed with predicted data \n",
    "lag24 = pd.DataFrame({'load_kw_lag24':y_pred_1}, index = test_data_2.index)\n",
    "test_data_2 = pd.concat([lag24, test_data_2], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd7f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_2 = test_data_2['load_kw']\n",
    "y_pred_2 = model_lgb.model.predict(xgb.DMatrix(test_data_2.drop('load_kw', axis=1)))\n",
    "mae2 = mean_absolute_error(y_test_2[24:], y_pred_2[:-24])\n",
    "print(mae2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2193ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = list(y_test_2.index)\n",
    "plt.plot(list(y_test_2[24:]))\n",
    "plt.plot(y_pred_2[:-24])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c435a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(abs(list(y_test_2[24:])-y_pred_2[:-24]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
